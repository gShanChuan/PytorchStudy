{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "pytorch1.6",
   "display_name": "Python [conda env:pytorch1.6]"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "训练误差 training error"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "泛化误差 generalization error"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# 模型选择"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "验证数据集 validation data set"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "__测试集__只能在所有超参数和模型参数选定后使用一次。不可以使用测试数据选择模型。"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "由于无法从训练误差估计泛化误差，因此也不应只依赖__训练数据__选择模型"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "从给定的训练集中随机选取一小部分作为验证集"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "* __K折交叉验证__"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "由于验证数据集不参与模型训练，当训练数据不够用时，预留大量的验证数据显得太奢侈。一种改善的方法是K折交叉验证（K-fold cross-validation）。在K折交叉验证中，我们把原始训练数据集分割成K个不重合的子数据集，然后我们做K次模型训练和验证。每一次，我们使用一个子数据集验证模型，并使用其他k-1个数据集来训练模型。在这K次训练和验证中，每次用来验证模型的子数据集都不同。最后，我们对这K次训练误差和验证误差分别求平均。"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# 欠拟合 underfiting 过拟合 overfitting"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "因素： \n",
    "* 模型复杂度\n",
    "* 训练数据集大小。"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}