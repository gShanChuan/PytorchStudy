{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "pytorch1.6",
   "display_name": "Python [conda env:pytorch1.6]"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# 不含模型参数的自定义层"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "自定义一个将输入减掉均值后输出的层，并将层的计算定义在forward函数里"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class CenterLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    def forward(self,x):\n",
    "        return x-x.mean()"
   ]
  },
  {
   "source": [
    "实例化此层，然后做前向计算"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([-2., -1.,  0.,  1.,  2.])"
      ]
     },
     "metadata": {},
     "execution_count": 56
    }
   ],
   "source": [
    "layer=CenterLayer()\n",
    "layer(torch.tensor([1,2,3,4,5],dtype=torch.float))"
   ]
  },
  {
   "source": [
    "我们也可以用它来构造更加复杂的模型"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "net=nn.Sequential(nn.Linear(8,128),CenterLayer())"
   ]
  },
  {
   "source": [
    "因为减去均值，所以均值接近于0"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "-3.725290298461914e-09"
      ]
     },
     "metadata": {},
     "execution_count": 58
    }
   ],
   "source": [
    "y = net(torch.rand(4, 8))\n",
    "y.mean().item()"
   ]
  },
  {
   "source": [
    "# 含模型参数的自定义层"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "自定义含模型参数的自定义层。其中模型参数可以通过训练学出。"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "如果一个Tensor是parameter，那么他会自动被添加到模型的参数列表。所以在自定义含模型参数的层时，我们应该将参数定义成paramter，还可以使用paramterList和paramterDict分别定义成参数的列表和字典"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "ParameterList接受一个Paramter实例的列表作为输入然后得到一个参数列表，在使用时可以用索引来访问某个参数，另外也可以使用append和extend在列表后面新增参数"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDense(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.params = nn.ParameterList([nn.Parameter(torch.rand(4,4)) for i in range(3)])\n",
    "        self.params.append(nn.Parameter(torch.rand(4,1)))\n",
    "\n",
    "    def foprward(self,x):\n",
    "        for i in range(len(self.params)):\n",
    "            x=torch.mm(x,self.params[i])\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "MyDense(\n  (params): ParameterList(\n      (0): Parameter containing: [torch.FloatTensor of size 4x4]\n      (1): Parameter containing: [torch.FloatTensor of size 4x4]\n      (2): Parameter containing: [torch.FloatTensor of size 4x4]\n      (3): Parameter containing: [torch.FloatTensor of size 4x1]\n  )\n)\n"
     ]
    }
   ],
   "source": [
    "net=MyDense()\n",
    "print(net)"
   ]
  },
  {
   "source": [
    "ParameterDict接受一个Parameter实例的字典作为输入然后得到一个参数字典，然后就可以按照字典的规则使用"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "class MyDictDense(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.params=nn.ParameterDict({\n",
    "            'linear1':nn.Parameter(torch.randn(4,4)),\n",
    "            'linear2':nn.Parameter(torch.randn(4,1))\n",
    "        })\n",
    "        self.params.update({'linear3':nn.Parameter(torch.rand(4,2))}) \n",
    "    def forward(self,x,choice='linear1'):\n",
    "        return torch.mm(x,self.params[choice])\n",
    "     "
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 61,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "MyDictDense(\n  (params): ParameterDict(\n      (linear1): Parameter containing: [torch.FloatTensor of size 4x4]\n      (linear2): Parameter containing: [torch.FloatTensor of size 4x1]\n      (linear3): Parameter containing: [torch.FloatTensor of size 4x2]\n  )\n)\n"
     ]
    }
   ],
   "source": [
    "net=MyDictDense()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[-0.6686,  0.0424,  1.5243, -1.5850]], grad_fn=<MmBackward>)\ntensor([[0.2494]], grad_fn=<MmBackward>)\ntensor([[2.1037, 2.9605]], grad_fn=<MmBackward>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(1, 4)\n",
    "print(net(x))\n",
    "print(net(x, 'linear2'))\n",
    "print(net(x, 'linear3'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}